"""
ç¬¬7ç« ï¼šçº¿æ€§å›å½’å®Œæ•´å®ç°
æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹é¡¹ç›®
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

class BostonHousingPredictor:
    """æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None
        self.target_name = 'MEDV'
        
    def load_data(self):
        """åŠ è½½æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®"""
        print("ğŸ“‚ åŠ è½½æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®...")
        
        try:
            # å°è¯•åŠ è½½sklearnå†…ç½®æ•°æ®é›†
            boston = load_boston()
            self.data = pd.DataFrame(boston.data, columns=boston.feature_names)
            self.data[self.target_name] = boston.target
            self.feature_names = boston.feature_names
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
            print(f"   - æ ·æœ¬æ•°é‡: {len(self.data)}")
            print(f"   - ç‰¹å¾æ•°é‡: {len(self.feature_names)}")
            print(f"   - ç›®æ ‡å˜é‡: {self.target_name} (æˆ¿ä»·ä¸­ä½æ•°)")
            
        except ImportError:
            # å¦‚æœsklearnç‰ˆæœ¬è¾ƒæ–°ï¼Œå¯èƒ½ä¸åŒ…å«bostonæ•°æ®é›†
            print("âš ï¸ sklearnå†…ç½®æ•°æ®é›†ä¸å¯ç”¨ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
            self.data = self._generate_sample_data()
            
        return self.data
    
    def _generate_sample_data(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„æˆ¿ä»·æ•°æ®"""
        np.random.seed(42)
        n_samples = 506
        
        # ç”Ÿæˆç‰¹å¾æ•°æ®
        features = {
            'CRIM': np.random.exponential(3.6, n_samples),  # çŠ¯ç½ªç‡
            'ZN': np.random.exponential(11.4, n_samples),   # ä½å®…ç”¨åœ°æ¯”ä¾‹
            'INDUS': np.random.normal(11.1, 6.9, n_samples),  # éé›¶å”®å•†ç”¨åœ°æ¯”ä¾‹
            'CHAS': np.random.binomial(1, 0.07, n_samples),   # æ²³è¾¹ä½ç½®
            'NOX': np.random.normal(0.55, 0.12, n_samples),   # æ°®æ°§åŒ–ç‰©æµ“åº¦
            'RM': np.random.normal(6.3, 0.7, n_samples),      # æˆ¿é—´æ•°
            'AGE': np.random.normal(68.6, 28.1, n_samples),   # æˆ¿å±‹å¹´é¾„
            'DIS': np.random.exponential(3.8, n_samples),     # è·ç¦»ä¸­å¿ƒè·ç¦»
            'RAD': np.random.choice(range(1, 25), n_samples), # äº¤é€šä¾¿åˆ©æ€§
            'TAX': np.random.normal(408, 169, n_samples),     # ç¨ç‡
            'PTRATIO': np.random.normal(18.5, 2.2, n_samples), # å¸ˆç”Ÿæ¯”
            'B': np.random.normal(356.7, 91.3, n_samples),    # é»‘äººæ¯”ä¾‹
            'LSTAT': np.random.normal(12.7, 7.1, n_samples)   # ä½æ”¶å…¥äººå£æ¯”ä¾‹
        }
        
        data = pd.DataFrame(features)
        self.feature_names = list(features.keys())
        
        # åŸºäºç‰¹å¾ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆæˆ¿ä»·ï¼‰
        price = (50 - 
                data['CRIM'] * 0.1 +
                data['RM'] * 8 -
                data['LSTAT'] * 0.5 -
                data['NOX'] * 15 +
                data['DIS'] * 0.8 +
                np.random.normal(0, 3, n_samples))
        
        data[self.target_name] = np.clip(price, 5, 50)  # é™åˆ¶åœ¨åˆç†èŒƒå›´
        
        return data
    
    def explore_data(self):
        """æ•°æ®æ¢ç´¢æ€§åˆ†æ"""
        print("\nğŸ” æ•°æ®æ¢ç´¢åˆ†æ...")
        
        # åŸºæœ¬ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(self.data.describe())
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_values = self.data.isnull().sum()
        if missing_values.sum() > 0:
            print("\nâš ï¸ ç¼ºå¤±å€¼æƒ…å†µ:")
            print(missing_values[missing_values > 0])
        else:
            print("\nâœ… æ— ç¼ºå¤±å€¼")
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ç›®æ ‡å˜é‡åˆ†å¸ƒ
        axes[0, 0].hist(self.data[self.target_name], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('æˆ¿ä»·åˆ†å¸ƒ', fontweight='bold')
        axes[0, 0].set_xlabel('æˆ¿ä»·ä¸­ä½æ•° (åƒç¾å…ƒ)')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        
        # 2. ç›¸å…³æ€§çƒ­åŠ›å›¾
        correlation_matrix = self.data.corr()
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                   ax=axes[0, 1], fmt='.2f', square=True)
        axes[0, 1].set_title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾', fontweight='bold')
        
        # 3. æˆ¿é—´æ•°vsæˆ¿ä»·
        axes[0, 2].scatter(self.data['RM'], self.data[self.target_name], alpha=0.6)
        axes[0, 2].set_title('æˆ¿é—´æ•° vs æˆ¿ä»·', fontweight='bold')
        axes[0, 2].set_xlabel('å¹³å‡æˆ¿é—´æ•°')
        axes[0, 2].set_ylabel('æˆ¿ä»·ä¸­ä½æ•°')
        
        # 4. çŠ¯ç½ªç‡vsæˆ¿ä»·
        axes[1, 0].scatter(self.data['CRIM'], self.data[self.target_name], alpha=0.6, color='red')
        axes[1, 0].set_title('çŠ¯ç½ªç‡ vs æˆ¿ä»·', fontweight='bold')
        axes[1, 0].set_xlabel('çŠ¯ç½ªç‡')
        axes[1, 0].set_ylabel('æˆ¿ä»·ä¸­ä½æ•°')
        
        # 5. ä¸æˆ¿ä»·ç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾
        correlations = correlation_matrix[self.target_name].abs().sort_values(ascending=False)[1:6]
        axes[1, 1].barh(range(len(correlations)), correlations.values)
        axes[1, 1].set_yticks(range(len(correlations)))
        axes[1, 1].set_yticklabels(correlations.index)
        axes[1, 1].set_title('ä¸æˆ¿ä»·ç›¸å…³æ€§æœ€é«˜çš„5ä¸ªç‰¹å¾', fontweight='bold')
        axes[1, 1].set_xlabel('ç›¸å…³ç³»æ•°(ç»å¯¹å€¼)')
        
        # 6. æˆ¿ä»·ç®±çº¿å›¾
        axes[1, 2].boxplot(self.data[self.target_name])
        axes[1, 2].set_title('æˆ¿ä»·åˆ†å¸ƒç®±çº¿å›¾', fontweight='bold')
        axes[1, 2].set_ylabel('æˆ¿ä»·ä¸­ä½æ•°')
        
        plt.tight_layout()
        plt.show()
        
        print("\nğŸ’¡ æ•°æ®æ´å¯Ÿ:")
        top_corr = correlation_matrix[self.target_name].abs().sort_values(ascending=False)[1:4]
        for feature, corr in top_corr.items():
            print(f"  â€¢ {feature}: ä¸æˆ¿ä»·ç›¸å…³æ€§ä¸º {corr:.3f}")
    
    def prepare_data(self, test_size=0.2, random_state=42):
        """å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®"""
        print("\nğŸ”§ å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®...")
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡
        X = self.data[self.feature_names]
        y = self.data[self.target_name]
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        
        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ!")
        print(f"   - è®­ç»ƒé›†å¤§å°: {len(self.X_train)}")
        print(f"   - æµ‹è¯•é›†å¤§å°: {len(self.X_test)}")
        print(f"   - ç‰¹å¾å·²æ ‡å‡†åŒ–")
        
        return self.X_train_scaled, self.X_test_scaled, self.y_train, self.y_test
    
    def train_model(self):
        """è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹"""
        print("\nğŸ¤– è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹...")
        
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        self.model = LinearRegression()
        self.model.fit(self.X_train_scaled, self.y_train)
        
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        
        # æ˜¾ç¤ºæ¨¡å‹å‚æ•°
        print(f"   - æˆªè·: {self.model.intercept_:.4f}")
        print("   - ç‰¹å¾ç³»æ•°:")
        for feature, coef in zip(self.feature_names, self.model.coef_):
            print(f"     {feature}: {coef:.4f}")
        
        return self.model
    
    def evaluate_model(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°...")
        
        # é¢„æµ‹
        y_train_pred = self.model.predict(self.X_train_scaled)
        y_test_pred = self.model.predict(self.X_test_scaled)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        train_r2 = r2_score(self.y_train, y_train_pred)
        test_r2 = r2_score(self.y_test, y_test_pred)
        
        train_rmse = np.sqrt(mean_squared_error(self.y_train, y_train_pred))
        test_rmse = np.sqrt(mean_squared_error(self.y_test, y_test_pred))
        
        train_mae = mean_absolute_error(self.y_train, y_train_pred)
        test_mae = mean_absolute_error(self.y_test, y_test_pred)
        
        print("ğŸ“ˆ è¯„ä¼°ç»“æœ:")
        print(f"è®­ç»ƒé›† RÂ² åˆ†æ•°: {train_r2:.4f}")
        print(f"æµ‹è¯•é›† RÂ² åˆ†æ•°: {test_r2:.4f}")
        print(f"è®­ç»ƒé›† RMSE: {train_rmse:.4f}")
        print(f"æµ‹è¯•é›† RMSE: {test_rmse:.4f}")
        print(f"è®­ç»ƒé›† MAE: {train_mae:.4f}")
        print(f"æµ‹è¯•é›† MAE: {test_mae:.4f}")
        
        # è¿‡æ‹Ÿåˆæ£€æŸ¥
        if train_r2 - test_r2 > 0.1:
            print("âš ï¸ å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
        else:
            print("âœ… æ¨¡å‹æ³›åŒ–æ€§èƒ½è‰¯å¥½")
        
        return {
            'train_r2': train_r2, 'test_r2': test_r2,
            'train_rmse': train_rmse, 'test_rmse': test_rmse,
            'train_mae': train_mae, 'test_mae': test_mae,
            'y_test_pred': y_test_pred
        }
    
    def visualize_results(self, evaluation_results):
        """å¯è§†åŒ–æ¨¡å‹ç»“æœ"""
        print("\nğŸ“ˆ å¯è§†åŒ–é¢„æµ‹ç»“æœ...")
        
        y_test_pred = evaluation_results['y_test_pred']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. é¢„æµ‹å€¼vsçœŸå®å€¼æ•£ç‚¹å›¾
        axes[0, 0].scatter(self.y_test, y_test_pred, alpha=0.6)
        axes[0, 0].plot([self.y_test.min(), self.y_test.max()], 
                       [self.y_test.min(), self.y_test.max()], 'r--', lw=2)
        axes[0, 0].set_xlabel('çœŸå®æˆ¿ä»·')
        axes[0, 0].set_ylabel('é¢„æµ‹æˆ¿ä»·')
        axes[0, 0].set_title('é¢„æµ‹å€¼ vs çœŸå®å€¼', fontweight='bold')
        axes[0, 0].text(0.05, 0.95, f'RÂ² = {evaluation_results["test_r2"]:.3f}', 
                       transform=axes[0, 0].transAxes, bbox=dict(boxstyle='round', facecolor='white'))
        
        # 2. æ®‹å·®å›¾
        residuals = self.y_test - y_test_pred
        axes[0, 1].scatter(y_test_pred, residuals, alpha=0.6)
        axes[0, 1].axhline(y=0, color='r', linestyle='--')
        axes[0, 1].set_xlabel('é¢„æµ‹æˆ¿ä»·')
        axes[0, 1].set_ylabel('æ®‹å·®')
        axes[0, 1].set_title('æ®‹å·®åˆ†å¸ƒå›¾', fontweight='bold')
        
        # 3. ç‰¹å¾é‡è¦æ€§
        feature_importance = abs(self.model.coef_)
        feature_names_sorted = [name for _, name in sorted(zip(feature_importance, self.feature_names), reverse=True)]
        importance_sorted = sorted(feature_importance, reverse=True)
        
        axes[1, 0].barh(range(len(feature_names_sorted)), importance_sorted)
        axes[1, 0].set_yticks(range(len(feature_names_sorted)))
        axes[1, 0].set_yticklabels(feature_names_sorted)
        axes[1, 0].set_xlabel('ç³»æ•°ç»å¯¹å€¼')
        axes[1, 0].set_title('ç‰¹å¾é‡è¦æ€§', fontweight='bold')
        
        # 4. é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
        axes[1, 1].hist(residuals, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        axes[1, 1].set_xlabel('é¢„æµ‹è¯¯å·®')
        axes[1, 1].set_ylabel('é¢‘æ•°')
        axes[1, 1].set_title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ', fontweight='bold')
        axes[1, 1].axvline(x=0, color='r', linestyle='--')
        
        plt.tight_layout()
        plt.show()
        
        print("ğŸ“Š å¯è§†åŒ–å®Œæˆ!")
    
    def predict_new_house(self, house_features):
        """é¢„æµ‹æ–°æˆ¿å­çš„ä»·æ ¼"""
        print("\nğŸ  é¢„æµ‹æ–°æˆ¿å­ä»·æ ¼...")
        
        # ç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®
        if isinstance(house_features, dict):
            house_features = [house_features[feature] for feature in self.feature_names]
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        house_features_scaled = self.scaler.transform([house_features])
        
        # é¢„æµ‹ä»·æ ¼
        predicted_price = self.model.predict(house_features_scaled)[0]
        
        print(f"ğŸ’° é¢„æµ‹æˆ¿ä»·: ${predicted_price:.2f}åƒç¾å…ƒ")
        
        return predicted_price
    
    def run_complete_project(self):
        """è¿è¡Œå®Œæ•´çš„æˆ¿ä»·é¢„æµ‹é¡¹ç›®"""
        print("ğŸ  å¼€å§‹æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹é¡¹ç›®...")
        print("=" * 60)
        
        # 1. åŠ è½½æ•°æ®
        self.load_data()
        
        # 2. æ•°æ®æ¢ç´¢
        self.explore_data()
        
        # 3. å‡†å¤‡æ•°æ®
        self.prepare_data()
        
        # 4. è®­ç»ƒæ¨¡å‹
        self.train_model()
        
        # 5. è¯„ä¼°æ¨¡å‹
        evaluation_results = self.evaluate_model()
        
        # 6. å¯è§†åŒ–ç»“æœ
        self.visualize_results(evaluation_results)
        
        # 7. ç¤ºä¾‹é¢„æµ‹
        print("\nğŸ”® ç¤ºä¾‹é¢„æµ‹:")
        example_house = {
            'CRIM': 0.1,      # ä½çŠ¯ç½ªç‡
            'ZN': 20.0,       # ä½å®…ç”¨åœ°
            'INDUS': 5.0,     # ä½å·¥ä¸šæ¯”ä¾‹
            'CHAS': 1,        # é è¿‘æ²³è¾¹
            'NOX': 0.4,       # ä½æ±¡æŸ“
            'RM': 7.0,        # 7ä¸ªæˆ¿é—´
            'AGE': 20.0,      # æˆ¿é¾„20å¹´
            'DIS': 5.0,       # è·ç¦»å¸‚ä¸­å¿ƒé€‚ä¸­
            'RAD': 3,         # äº¤é€šä¾¿åˆ©
            'TAX': 300,       # é€‚ä¸­ç¨ç‡
            'PTRATIO': 15.0,  # å¥½çš„å¸ˆç”Ÿæ¯”
            'B': 390.0,       # ç¤¾åŒºæŒ‡æ ‡
            'LSTAT': 5.0      # ä½æ”¶å…¥äººå£æ¯”ä¾‹ä½
        }
        
        predicted_price = self.predict_new_house(example_house)
        
        print("\nğŸ¯ é¡¹ç›®æ€»ç»“:")
        print(f"  â€¢ æ•°æ®é›†å¤§å°: {len(self.data)} å¥—æˆ¿å±‹")
        print(f"  â€¢ ç‰¹å¾æ•°é‡: {len(self.feature_names)} ä¸ª")
        print(f"  â€¢ æ¨¡å‹RÂ²åˆ†æ•°: {evaluation_results['test_r2']:.3f}")
        print(f"  â€¢ å¹³å‡ç»å¯¹è¯¯å·®: {evaluation_results['test_mae']:.2f}åƒç¾å…ƒ")
        print("\nğŸ‰ æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹é¡¹ç›®å®Œæˆ!")
        
        return self

def run_gradient_descent_demo():
    """æ¢¯åº¦ä¸‹é™ç®—æ³•æ¼”ç¤º"""
    print("\n" + "="*60)
    print("ğŸ“ˆ æ¢¯åº¦ä¸‹é™ç®—æ³•å¯è§†åŒ–æ¼”ç¤º")
    print("="*60)
    
    # ç”Ÿæˆç®€å•çš„çº¿æ€§æ•°æ®
    np.random.seed(42)
    X = np.random.randn(100, 1)
    y = 4 + 3 * X.flatten() + np.random.randn(100) * 0.5
    
    # æ‰‹åŠ¨å®ç°æ¢¯åº¦ä¸‹é™
    def gradient_descent(X, y, learning_rate=0.01, n_iterations=1000):
        m = len(y)
        theta = np.random.randn(2, 1)  # éšæœºåˆå§‹åŒ–å‚æ•°
        X_b = np.c_[np.ones((m, 1)), X]  # æ·»åŠ åç½®é¡¹
        
        cost_history = []
        theta_history = []
        
        for iteration in range(n_iterations):
            # é¢„æµ‹
            y_pred = X_b.dot(theta).flatten()
            
            # è®¡ç®—æŸå¤±
            cost = np.mean((y_pred - y) ** 2) / 2
            cost_history.append(cost)
            theta_history.append(theta.copy())
            
            # è®¡ç®—æ¢¯åº¦
            gradients = X_b.T.dot(y_pred - y) / m
            
            # æ›´æ–°å‚æ•°
            theta = theta - learning_rate * gradients.reshape(-1, 1)
        
        return theta, cost_history, theta_history
    
    # è¿è¡Œæ¢¯åº¦ä¸‹é™
    theta_final, cost_history, theta_history = gradient_descent(X, y)
    
    # å¯è§†åŒ–ç»“æœ
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # 1. æ•°æ®å’Œæ‹Ÿåˆçº¿
    axes[0].scatter(X, y, alpha=0.6, label='æ•°æ®ç‚¹')
    X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
    X_plot_b = np.c_[np.ones((100, 1)), X_plot]
    y_plot = X_plot_b.dot(theta_final).flatten()
    axes[0].plot(X_plot, y_plot, 'r-', linewidth=2, label='æ‹Ÿåˆç›´çº¿')
    axes[0].set_xlabel('X')
    axes[0].set_ylabel('y')
    axes[0].set_title('çº¿æ€§å›å½’ç»“æœ', fontweight='bold')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # 2. æŸå¤±å‡½æ•°å˜åŒ–
    axes[1].plot(cost_history, 'b-', linewidth=2)
    axes[1].set_xlabel('è¿­ä»£æ¬¡æ•°')
    axes[1].set_ylabel('æŸå¤±å€¼')
    axes[1].set_title('æ¢¯åº¦ä¸‹é™è¿‡ç¨‹', fontweight='bold')
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"âœ… æ¢¯åº¦ä¸‹é™å®Œæˆ!")
    print(f"   - æœ€ç»ˆå‚æ•°: Î¸â‚€={theta_final[0][0]:.3f}, Î¸â‚={theta_final[1][0]:.3f}")
    print(f"   - æœ€ç»ˆæŸå¤±: {cost_history[-1]:.6f}")
    print(f"   - è¿­ä»£æ¬¡æ•°: {len(cost_history)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ  ç¬¬7ç« ï¼šçº¿æ€§å›å½’ä¸æˆ¿ä»·é¢„æµ‹")
    print("=" * 60)
    
    # 1. è¿è¡Œå®Œæ•´é¡¹ç›®
    predictor = BostonHousingPredictor()
    predictor.run_complete_project()
    
    # 2. æ¢¯åº¦ä¸‹é™æ¼”ç¤º
    run_gradient_descent_demo()
    
    print("\nğŸ“ å­¦ä¹ æ€»ç»“:")
    print("  â€¢ çº¿æ€§å›å½’æ˜¯é¢„æµ‹è¿ç»­å€¼çš„åŸºç¡€ç®—æ³•")
    print("  â€¢ æ¢¯åº¦ä¸‹é™æ˜¯å¯»æ‰¾æœ€ä¼˜å‚æ•°çš„æœ‰æ•ˆæ–¹æ³•")
    print("  â€¢ ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é¢„å¤„ç†å¾ˆé‡è¦")
    print("  â€¢ æ¨¡å‹è¯„ä¼°å¸®åŠ©æˆ‘ä»¬äº†è§£é¢„æµ‹æ€§èƒ½")
    
    return predictor

if __name__ == "__main__":
    predictor = main()
